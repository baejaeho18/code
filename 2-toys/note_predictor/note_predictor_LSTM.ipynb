{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WFqV8kLN0Lc0"
      },
      "outputs": [],
      "source": [
        "## Sequence Data\n",
        "scales = ['C4', 'C4', 'G4', 'G4', 'A4', 'A4', 'G4', 'F4', 'F4', 'E4', 'E4', 'D4', 'D4', 'C4',\n",
        "          'G4', 'G4', 'F4', 'F4', 'E4', 'E4', 'D4', 'G4', 'G4', 'F4', 'F4', 'E4', 'E4', 'D4',\n",
        "          'C4', 'C4', 'G4', 'G4', 'A4', 'A4', 'G4', 'F4', 'F4', 'E4', 'E4', 'D4', 'D4', 'C4']\n",
        "durations = [4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 8,\n",
        "             4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 8,\n",
        "             4, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 4, 8]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Make an audio file to play\n",
        "!pip install pretty_midi\n",
        "import numpy as np\n",
        "import pretty_midi as pm\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio\n",
        "\n",
        "def midi(predicted_notes):\n",
        "  midi_data = pm.PrettyMIDI()\n",
        "\n",
        "  piano_program = pm.instrument_name_to_program('Acoustic Grand Piano')\n",
        "  piano = pm.Instrument(program=piano_program)\n",
        "\n",
        "  currentTime = 0\n",
        "  seconds4Quarter = 0.5/4.\n",
        "  for scale, duration in predicted_notes:\n",
        "    note_duration = seconds4Quarter * duration\n",
        "    note = pm.Note(velocity=100, pitch=scale, start=currentTime, end=currentTime + note_duration)\n",
        "    currentTime += note_duration\n",
        "    piano.notes.append(note)\n",
        "  midi_data.instruments.append(piano)\n",
        "  audio_data = midi_data.synthesize()\n",
        "  Audio(audio_data, rate=44100)\n",
        "  sf.write('output_audio.wav', audio_data, 44100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n68oa9L80NBw",
        "outputId": "f0ec5221-aba1-4f7a-c675-c52ac2c0aabb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.25.2)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592289 sha256=45689efc4c7e1d3b0caab5d374db37eb249c5122eff989d9564f62cf2d447410\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: packaging, mido, pretty_midi\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed mido-1.3.2 packaging-23.2 pretty_midi-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Data prepration\n",
        "def one_hot_encode_notes(notes):\n",
        "  num_scales = 13\n",
        "  num_durations = 2\n",
        "  total_features = num_scales + num_durations\n",
        "\n",
        "  one_hot_encoded = np.zeros((len(notes), total_features), dtype=int)\n",
        "\n",
        "  for i, (scale_num, duration) in enumerate(notes):\n",
        "    scale_index = scale_num - 60\n",
        "    duration_index = 13 if duration == 4 else 14\n",
        "\n",
        "    one_hot_encoded[i, scale_index] = 1\n",
        "    one_hot_encoded[i, duration_index] = 1\n",
        "  return one_hot_encoded\n",
        "\n",
        "def prepare_sequence(encoded_notes, sequence_length=4):\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(len(encoded_notes) - sequence_length):\n",
        "    sequence_in = encoded_notes[i:i + sequence_length]\n",
        "    sequence_out = encoded_notes[i + sequence_length]\n",
        "    X.append(sequence_in)\n",
        "    y.append(sequence_out)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "note_numbers = []\n",
        "for scale in scales:\n",
        "  note_numbers.append(pm.note_name_to_number(scale))\n",
        "notes = list(zip(note_numbers, durations))\n",
        "encoded_notes = one_hot_encode_notes(notes)\n",
        "\n",
        "sequence_length = 4\n",
        "X, y = prepare_sequence(encoded_notes, sequence_length)"
      ],
      "metadata": {
        "id": "LpnWYg0L0a6y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Design: LSTM\n",
        "### Make the model stateful\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "sequence_length = 4\n",
        "num_features = 15\n",
        "num_scale_units = 13\n",
        "num_duration_units = 2\n",
        "\n",
        "inputs = Input(batch_shape=(1, sequence_length, num_features))\n",
        "lstm_out = LSTM(64, return_sequences=False, stateful=True)(inputs)\n",
        "scale_output = Dense(num_scale_units, activation='softmax', name='scale_output')(lstm_out)\n",
        "duration_output = Dense(num_duration_units, activation='softmax', name='duration_output')(lstm_out)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=[scale_output, duration_output])\n",
        "model.compile(optimizer='Adam',\n",
        "              loss={'scale_output':'categorical_crossentropy', 'duration_output':'categorical_crossentropy'},\n",
        "              metrics={'scale_output':'accuracy', 'duration_output':'accuracy'})\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV8BNvje0yl5",
        "outputId": "58c5dfd8-4a72-437c-b46e-1885c062bacf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(1, 4, 15)]                 0         []                            \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (1, 64)                      20480     ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " scale_output (Dense)        (1, 13)                      845       ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " duration_output (Dense)     (1, 2)                       130       ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21455 (83.81 KB)\n",
            "Trainable params: 21455 (83.81 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model training\n",
        "### reuse the model's states at every epoch\n",
        "num_epochs = 2000\n",
        "for epoch_idx in range(num_epochs):\n",
        "  model.reset_states()\n",
        "  if epoch_idx % 100 == 0:\n",
        "    print('epochs : ' + str(epoch_idx))\n",
        "    model.fit(X, [y[:, 0:num_scale_units], y[:, num_scale_units:num_features]],\n",
        "            epochs=1, batch_size=1, verbose=2, validation_split=0.2)\n",
        "  else:\n",
        "    model.fit(X, [y[:, 0:num_scale_units], y[:, num_scale_units:num_features]],\n",
        "            epochs=1, batch_size=1, verbose=0, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMYBcq2D1n7b",
        "outputId": "c38659be-932b-4e81-8e3b-5041243bc1e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs : 0\n",
            "30/30 - 0s - loss: 0.1153 - scale_output_loss: 0.0453 - duration_output_loss: 0.0700 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1305 - val_scale_output_loss: 5.4389e-06 - val_duration_output_loss: 0.1305 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 280ms/epoch - 9ms/step\n",
            "epochs : 50\n",
            "30/30 - 0s - loss: 0.1091 - scale_output_loss: 0.0440 - duration_output_loss: 0.0651 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1376 - val_scale_output_loss: 9.9538e-06 - val_duration_output_loss: 0.1376 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 233ms/epoch - 8ms/step\n",
            "epochs : 100\n",
            "30/30 - 0s - loss: 0.1154 - scale_output_loss: 0.0473 - duration_output_loss: 0.0681 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1339 - val_scale_output_loss: 5.4389e-06 - val_duration_output_loss: 0.1339 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 201ms/epoch - 7ms/step\n",
            "epochs : 150\n",
            "30/30 - 0s - loss: 0.1122 - scale_output_loss: 0.0470 - duration_output_loss: 0.0652 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1367 - val_scale_output_loss: 7.6442e-06 - val_duration_output_loss: 0.1367 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 324ms/epoch - 11ms/step\n",
            "epochs : 200\n",
            "30/30 - 0s - loss: 0.1123 - scale_output_loss: 0.0459 - duration_output_loss: 0.0663 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1394 - val_scale_output_loss: 7.1227e-06 - val_duration_output_loss: 0.1394 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 203ms/epoch - 7ms/step\n",
            "epochs : 250\n",
            "30/30 - 0s - loss: 0.1112 - scale_output_loss: 0.0464 - duration_output_loss: 0.0649 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1381 - val_scale_output_loss: 3.8296e-06 - val_duration_output_loss: 0.1381 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 205ms/epoch - 7ms/step\n",
            "epochs : 300\n",
            "30/30 - 0s - loss: 0.1154 - scale_output_loss: 0.0476 - duration_output_loss: 0.0678 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1318 - val_scale_output_loss: 4.4405e-06 - val_duration_output_loss: 0.1318 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 195ms/epoch - 6ms/step\n",
            "epochs : 350\n",
            "30/30 - 0s - loss: 0.1128 - scale_output_loss: 0.0464 - duration_output_loss: 0.0664 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1316 - val_scale_output_loss: 4.2319e-06 - val_duration_output_loss: 0.1316 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 204ms/epoch - 7ms/step\n",
            "epochs : 400\n",
            "30/30 - 0s - loss: 0.1128 - scale_output_loss: 0.0462 - duration_output_loss: 0.0667 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1303 - val_scale_output_loss: 5.2898e-06 - val_duration_output_loss: 0.1303 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 210ms/epoch - 7ms/step\n",
            "epochs : 450\n",
            "30/30 - 0s - loss: 0.1114 - scale_output_loss: 0.0476 - duration_output_loss: 0.0638 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1391 - val_scale_output_loss: 1.8924e-06 - val_duration_output_loss: 0.1391 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 191ms/epoch - 6ms/step\n",
            "epochs : 500\n",
            "30/30 - 0s - loss: 0.1133 - scale_output_loss: 0.0465 - duration_output_loss: 0.0668 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1286 - val_scale_output_loss: 1.0729e-06 - val_duration_output_loss: 0.1286 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 180ms/epoch - 6ms/step\n",
            "epochs : 550\n",
            "30/30 - 0s - loss: 0.1292 - scale_output_loss: 0.0650 - duration_output_loss: 0.0641 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1394 - val_scale_output_loss: 1.3113e-06 - val_duration_output_loss: 0.1394 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 202ms/epoch - 7ms/step\n",
            "epochs : 600\n",
            "30/30 - 0s - loss: 0.1132 - scale_output_loss: 0.0480 - duration_output_loss: 0.0653 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1328 - val_scale_output_loss: 3.8892e-06 - val_duration_output_loss: 0.1328 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 176ms/epoch - 6ms/step\n",
            "epochs : 650\n",
            "30/30 - 0s - loss: 0.1111 - scale_output_loss: 0.0465 - duration_output_loss: 0.0647 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1408 - val_scale_output_loss: 5.2899e-06 - val_duration_output_loss: 0.1408 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 203ms/epoch - 7ms/step\n",
            "epochs : 700\n",
            "30/30 - 0s - loss: 0.1140 - scale_output_loss: 0.0467 - duration_output_loss: 0.0674 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1328 - val_scale_output_loss: 3.4570e-06 - val_duration_output_loss: 0.1328 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 199ms/epoch - 7ms/step\n",
            "epochs : 750\n",
            "30/30 - 0s - loss: 0.1145 - scale_output_loss: 0.0481 - duration_output_loss: 0.0664 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1374 - val_scale_output_loss: 1.9669e-06 - val_duration_output_loss: 0.1374 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 290ms/epoch - 10ms/step\n",
            "epochs : 800\n",
            "30/30 - 0s - loss: 0.1121 - scale_output_loss: 0.0471 - duration_output_loss: 0.0650 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1480 - val_scale_output_loss: 6.5713e-06 - val_duration_output_loss: 0.1480 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 193ms/epoch - 6ms/step\n",
            "epochs : 850\n",
            "30/30 - 0s - loss: 0.1130 - scale_output_loss: 0.0476 - duration_output_loss: 0.0655 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1333 - val_scale_output_loss: 1.9818e-06 - val_duration_output_loss: 0.1333 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 193ms/epoch - 6ms/step\n",
            "epochs : 900\n",
            "30/30 - 0s - loss: 0.1395 - scale_output_loss: 0.0743 - duration_output_loss: 0.0652 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1420 - val_scale_output_loss: 1.0580e-06 - val_duration_output_loss: 0.1420 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 193ms/epoch - 6ms/step\n",
            "epochs : 950\n",
            "30/30 - 0s - loss: 0.1050 - scale_output_loss: 0.0385 - duration_output_loss: 0.0665 - scale_output_accuracy: 1.0000 - duration_output_accuracy: 0.9667 - val_loss: 0.1333 - val_scale_output_loss: 9.8347e-07 - val_duration_output_loss: 0.1333 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 187ms/epoch - 6ms/step\n",
            "epochs : 1000\n",
            "30/30 - 0s - loss: 0.1165 - scale_output_loss: 0.0486 - duration_output_loss: 0.0679 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1548 - val_scale_output_loss: 8.6276e-06 - val_duration_output_loss: 0.1548 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 242ms/epoch - 8ms/step\n",
            "epochs : 1050\n",
            "30/30 - 0s - loss: 0.1110 - scale_output_loss: 0.0460 - duration_output_loss: 0.0651 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1370 - val_scale_output_loss: 1.8328e-06 - val_duration_output_loss: 0.1370 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 185ms/epoch - 6ms/step\n",
            "epochs : 1100\n",
            "30/30 - 0s - loss: 0.1116 - scale_output_loss: 0.0471 - duration_output_loss: 0.0645 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1402 - val_scale_output_loss: 1.4752e-06 - val_duration_output_loss: 0.1402 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 199ms/epoch - 7ms/step\n",
            "epochs : 1150\n",
            "30/30 - 0s - loss: 0.1119 - scale_output_loss: 0.0469 - duration_output_loss: 0.0650 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1389 - val_scale_output_loss: 9.2387e-07 - val_duration_output_loss: 0.1389 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 188ms/epoch - 6ms/step\n",
            "epochs : 1200\n",
            "30/30 - 0s - loss: 0.1119 - scale_output_loss: 0.0472 - duration_output_loss: 0.0647 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1353 - val_scale_output_loss: 6.2585e-07 - val_duration_output_loss: 0.1353 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 179ms/epoch - 6ms/step\n",
            "epochs : 1250\n",
            "30/30 - 0s - loss: 0.1119 - scale_output_loss: 0.0469 - duration_output_loss: 0.0650 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1402 - val_scale_output_loss: 1.0729e-06 - val_duration_output_loss: 0.1402 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 194ms/epoch - 6ms/step\n",
            "epochs : 1300\n",
            "30/30 - 0s - loss: 0.1111 - scale_output_loss: 0.0473 - duration_output_loss: 0.0638 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1368 - val_scale_output_loss: 7.1525e-07 - val_duration_output_loss: 0.1368 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 333ms/epoch - 11ms/step\n",
            "epochs : 1350\n",
            "30/30 - 0s - loss: 0.1121 - scale_output_loss: 0.0471 - duration_output_loss: 0.0650 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1493 - val_scale_output_loss: 1.2964e-06 - val_duration_output_loss: 0.1493 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 190ms/epoch - 6ms/step\n",
            "epochs : 1400\n",
            "30/30 - 0s - loss: 0.1129 - scale_output_loss: 0.0481 - duration_output_loss: 0.0648 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1381 - val_scale_output_loss: 7.4506e-07 - val_duration_output_loss: 0.1381 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 286ms/epoch - 10ms/step\n",
            "epochs : 1450\n",
            "30/30 - 0s - loss: 0.1143 - scale_output_loss: 0.0474 - duration_output_loss: 0.0668 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1348 - val_scale_output_loss: 1.3560e-06 - val_duration_output_loss: 0.1348 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 188ms/epoch - 6ms/step\n",
            "epochs : 1500\n",
            "30/30 - 0s - loss: 0.1116 - scale_output_loss: 0.0471 - duration_output_loss: 0.0646 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1474 - val_scale_output_loss: 6.5565e-07 - val_duration_output_loss: 0.1474 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 180ms/epoch - 6ms/step\n",
            "epochs : 1550\n",
            "30/30 - 0s - loss: 0.1618 - scale_output_loss: 0.0868 - duration_output_loss: 0.0750 - scale_output_accuracy: 0.9000 - duration_output_accuracy: 0.9333 - val_loss: 0.1749 - val_scale_output_loss: 2.2201e-05 - val_duration_output_loss: 0.1749 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 205ms/epoch - 7ms/step\n",
            "epochs : 1600\n",
            "30/30 - 0s - loss: 0.1105 - scale_output_loss: 0.0473 - duration_output_loss: 0.0632 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1474 - val_scale_output_loss: 6.1988e-06 - val_duration_output_loss: 0.1474 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 221ms/epoch - 7ms/step\n",
            "epochs : 1650\n",
            "30/30 - 0s - loss: 0.1130 - scale_output_loss: 0.0464 - duration_output_loss: 0.0666 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1536 - val_scale_output_loss: 5.3495e-06 - val_duration_output_loss: 0.1536 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 208ms/epoch - 7ms/step\n",
            "epochs : 1700\n",
            "30/30 - 0s - loss: 0.1134 - scale_output_loss: 0.0478 - duration_output_loss: 0.0655 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1393 - val_scale_output_loss: 6.5863e-06 - val_duration_output_loss: 0.1393 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 229ms/epoch - 8ms/step\n",
            "epochs : 1750\n",
            "30/30 - 0s - loss: 0.1114 - scale_output_loss: 0.0465 - duration_output_loss: 0.0650 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1422 - val_scale_output_loss: 1.7434e-06 - val_duration_output_loss: 0.1422 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 214ms/epoch - 7ms/step\n",
            "epochs : 1800\n",
            "30/30 - 0s - loss: 0.1148 - scale_output_loss: 0.0488 - duration_output_loss: 0.0661 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1314 - val_scale_output_loss: 2.8461e-06 - val_duration_output_loss: 0.1314 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 186ms/epoch - 6ms/step\n",
            "epochs : 1850\n",
            "30/30 - 0s - loss: 0.1123 - scale_output_loss: 0.0476 - duration_output_loss: 0.0647 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1380 - val_scale_output_loss: 1.5497e-06 - val_duration_output_loss: 0.1380 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 196ms/epoch - 7ms/step\n",
            "epochs : 1900\n",
            "30/30 - 0s - loss: 0.1115 - scale_output_loss: 0.0469 - duration_output_loss: 0.0647 - scale_output_accuracy: 0.9667 - duration_output_accuracy: 0.9667 - val_loss: 0.1379 - val_scale_output_loss: 9.9838e-07 - val_duration_output_loss: 0.1379 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 229ms/epoch - 8ms/step\n",
            "epochs : 1950\n",
            "30/30 - 0s - loss: 0.1130 - scale_output_loss: 0.0468 - duration_output_loss: 0.0662 - scale_output_accuracy: 0.9333 - duration_output_accuracy: 0.9667 - val_loss: 0.1410 - val_scale_output_loss: 1.3411e-06 - val_duration_output_loss: 0.1410 - val_scale_output_accuracy: 1.0000 - val_duration_output_accuracy: 0.8750 - 207ms/epoch - 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model prediction test\n",
        "### with only first four notes\n",
        "prediction_length = y.shape[0]\n",
        "\n",
        "given_notes = X[0:1]\n",
        "input_sequence = given_notes\n",
        "predicted_notes = []\n",
        "for note in given_notes[0]:\n",
        "  scale = np.argmax(note[0:num_scale_units], axis=-1) + 60\n",
        "  duration = 4 if np.argmax(note[num_scale_units:num_features], axis=-1) == 0 else 8\n",
        "\n",
        "for i in range(prediction_length):\n",
        "  scale_pred, duration_pred = model.predict(input_sequence)\n",
        "  next_scale = np.argmax(scale_pred, axis=-1)\n",
        "  next_duration = 4 if np.argmax(duration_pred, axis=-1) == 0 else 8\n",
        "  predicted_notes.append((next_scale.item() + 60, next_duration))\n",
        "\n",
        "  next_note_encoded = np.zeros((1, 1, given_notes.shape[2]))\n",
        "  next_note_encoded[0, 0, next_scale] = 1\n",
        "  next_note_encoded[0, 0, -2 if next_duration == 4 else -1] = 1\n",
        "\n",
        "  input_sequence = np.concatenate((input_sequence[:, 1:, :], next_note_encoded), axis=1)\n",
        "\n",
        "print(predicted_notes)\n",
        "midi(predicted_notes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY2E18Px2sW1",
        "outputId": "317038fd-6e39-4c1f-a0d9-8979343d2090"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 484ms/step\n",
            "1/1 [==============================] - 0s 429ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "[(69, 4), (69, 4), (67, 8), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(notes[4:])\n",
        "print(predicted_notes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISyrmyfA2zs1",
        "outputId": "6414521b-525d-4322-b565-1eee6a2b7d0a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(69, 4), (69, 4), (67, 8), (65, 4), (65, 4), (64, 4), (64, 4), (62, 4), (62, 4), (60, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (60, 4), (60, 4), (67, 4), (67, 4), (69, 4), (69, 4), (67, 8), (65, 4), (65, 4), (64, 4), (64, 4), (62, 4), (62, 4), (60, 8)]\n",
            "[(69, 4), (69, 4), (67, 8), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4), (65, 4), (65, 4), (64, 4), (64, 4), (62, 8), (67, 4), (67, 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gFnmEJU69IIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}