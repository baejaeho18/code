{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq_xfOABziep"
   },
   "source": [
    "# Week 10. Clustering \n",
    "\n",
    "## Exercise(1) Apply <font color='blue'>PCA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRdnAEkeziex",
    "outputId": "5ed192a6-7a88-4fd9-b556-7901c94954dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('... loading data')\n",
    "with open('data/mnist.pkl', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_9EsVPeziez"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train_set\n",
    "test_x, test_y = test_set\n",
    "\n",
    "train_x = pd.DataFrame(train_x)\n",
    "train_y = pd.DataFrame(train_y, columns=['label'])\n",
    "test_x = pd.DataFrame(test_x)\n",
    "test_y = pd.DataFrame(test_y, columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_Vc9qM1zie0"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# YOUR CODE STARTS HERE to get PCA_train_x and PCA_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zqf7leDuzie0"
   },
   "outputs": [],
   "source": [
    "print('PCA_train_x shape: ', PCA_train_x.shape)\n",
    "print('PCA_test_x shape: ', PCA_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsReldkpzie0"
   },
   "outputs": [],
   "source": [
    "## Plot on the graph\n",
    "# YOUR CODE STARTS HERE\n",
    "# plt.scatter(...)\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "\n",
    "plt.title('Visualizing MNIST through PCA', fontsize=24);\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IL3tNRiVzie0"
   },
   "source": [
    "### Let's use part of train_x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aax04iBzie1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "# sub_PCA_train_x = ...\n",
    "print('sub_PCA_train_x.shape: ', sub_PCA_train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kif5SFJizie1"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "# sub_PCA_test_x = ...\n",
    "print('sub_PCA_test_x.shape: ', sub_PCA_test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOzSKNc-zie1"
   },
   "source": [
    "## Exercise(2) - Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEVGDX-Gzie2"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "# hier = ...\n",
    "\n",
    "## Plot \n",
    "plt.scatter(sub_PCA_train_x[:, 0], sub_PCA_train_x[:, 1], c=train_y['label'][:1000], cmap='Spectral', alpha=0.5)\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title(\"Clustering with \")\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoyAFIC2zie2"
   },
   "source": [
    "----\n",
    "## Exercise(3) k-means scratch\n",
    "### <font color='brown'>3-Step(1) Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GwnD0OOzie2",
    "outputId": "5fc18115-c2bb-4809-d2c4-3c6aedffd9fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 4],\n",
       "       [1, 3, 4],\n",
       "       [1, 3, 4]])"
      ]
     },
     "execution_count": 440,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 3, 4])\n",
    "A = np.tile(a, (3,1))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_RJd-Vkzie3"
   },
   "source": [
    "two popular normalization methods\n",
    "* min-max normalization\n",
    "* mean-std normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pk4DmKPvzie4"
   },
   "outputs": [],
   "source": [
    "def apply_normalizer(dataset, offset, divisor):\n",
    "    dataset_normalized = np.zeros(dataset.shape)\n",
    "    N = dataset.shape[0]\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # dataset_normalized = ...\n",
    "    # dataset_normalized = ...\n",
    "\n",
    "    return dataset_normalized\n",
    "\n",
    "\n",
    "def normalize_minmax(dataset):\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # minval = dataset.min(0)\n",
    "    # maxval = dataset.max(0)\n",
    "    \n",
    "    # dataset_normalized = ...\n",
    "\n",
    "    return dataset_normalized, minval, maxval-minval\n",
    "\n",
    "\n",
    "def normalize_meanstd(dataset):\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # meanval = ...\n",
    "    # stdval = ...\n",
    "\n",
    "    # dataset_normalized = ...\n",
    "\n",
    "    return dataset_normalized, meanval, stdval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmmifihYzie4"
   },
   "outputs": [],
   "source": [
    "normalized_PCA_train_x, off, div = normalize_minmax(sub_PCA_train_x)\n",
    "print(\"Original data: \", sub_PCA_train_x[0], '\\nNormalized data: ', normalized_PCA_train_x[0])\n",
    "print(\"offset:\", off, \";  divisor:\", div, '\\n')\n",
    "\n",
    "normalized_PCA_train_x, off, div = normalize_meanstd(sub_PCA_train_x)\n",
    "print(\"Original data: \", sub_PCA_train_x[0], '\\nNormalized data: ', normalized_PCA_train_x[0])\n",
    "print(\"offset:\", off, \";  divisor:\", div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-Xqtw9Vzie4"
   },
   "outputs": [],
   "source": [
    "plt.scatter(normalized_PCA_train_x[:, 0], normalized_PCA_train_x[:, 1], cmap='Spectral', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CCW2LPazie5"
   },
   "source": [
    " <font color='blue'>\n",
    "\n",
    "**Q1: In the normalization methods, what is the meaning of offset and divisor, respectively?** <br>\n",
    "\n",
    "**Q2: After normalization, how does the data range change?** <br>\n",
    "\n",
    " <font color='black'>\n",
    "\n",
    "Hint: Try np.mean(X_normalized, axis=0), np.std(X_normalized, axis=0), np.min(X_normalized, axis=0), np.max(X_normalized, axis=0), np.median(X_normalized, axis=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCT4LVDWzie5"
   },
   "outputs": [],
   "source": [
    "# a distance function\n",
    "def Euclidean_distance(vecA, vecB):\n",
    "    # YOUR CODE STARTS HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyOdznkdzie5"
   },
   "source": [
    "### <font color='brown'>3-Step(2). Initialize centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wnASVGbzie5",
    "outputId": "705b1176-64e8-44b6-ba63-f5113984496a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many cluster do you want? 10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "k = int(input(\"How many cluster do you want? \"))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTzSYjxWzie6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def init_centroids_random(dataset, k):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dataset -- Numpy array of PCA applied data\n",
    "    k -- the number of clusters\n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # init_centroids = ...\n",
    "    \n",
    "    # for ...\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAk7uzUwzie6"
   },
   "outputs": [],
   "source": [
    "def init_centroids_index(dataset, k):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dataset -- Numpy array of PCA applied data\n",
    "    k -- the number of clusters\n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "    for i in range(k):  # first k instances become the initial centroids\n",
    "        # ...\n",
    "        \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XA-5YQ5Szie6"
   },
   "outputs": [],
   "source": [
    "# initialize_centroids(centroids, sub_PCA_train_x)\n",
    "centroids = init_centroids_random(centroids, sub_PCA_train_x, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPX2l-Fkzie6"
   },
   "outputs": [],
   "source": [
    "## Change centroids value to dataframe. \n",
    "# cet_df = ...\n",
    "# cet_df.columns ...\n",
    "cet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozoSa-XZzie7"
   },
   "outputs": [],
   "source": [
    "## Plot random centroids on the dataset\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4cuOVHYzie7"
   },
   "source": [
    "### <font color='brown'>3-Step(3). (Re)assigning every datas to its _closest centroid_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5yKtes8zie7"
   },
   "outputs": [],
   "source": [
    "def re_assign_data(dataset, centroids):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dataset -- Numpy array of PCA applied data\n",
    "    centroids -- A dictionary of centroids\n",
    "    \"\"\"\n",
    "    \n",
    "    # (Re)assigning every instance to its closest centroid\n",
    "    for row in dataset:\n",
    "        ## YOUR CODE STARTS HERE\n",
    "        # Calculate euclidean distance between each centroid and each data.\n",
    "        # distances_to_centroids = ...\n",
    "        \n",
    "        # Find the centroid with a minimum distance \n",
    "        # membership = ...\n",
    "        # ...\n",
    "        \n",
    "    return memberships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkYXnmuFzie7"
   },
   "source": [
    "### <font color='brown'>3-Step(4). Recalculate average of each cluster and calculate SSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_7vVyZ3zie8"
   },
   "outputs": [],
   "source": [
    "def re_calc_avg_sse(centroids, memberships):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    centroids -- A dictionary of centroids\n",
    "    memberships -- A dictionary data which is clustered by key(key: clustered group, value: values of that group)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Re-calculate the average of each cluster and calculate SSE.\n",
    "    for membership in cluster_memberships:\n",
    "        ## YOUR CODE STARTS HERE\n",
    "        # centroids[membership] = ...\n",
    "\n",
    "        for row in cluster_memberships[membership]:\n",
    "            # curr_sse += ...\n",
    "    \n",
    "    return centroids, curr_sse            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlmRwvMhzie8"
   },
   "source": [
    "###  <font color='brown'>3-Step(5). Iterate STEP3 and STEP4 until SSE is less than `tol` value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfb1Sq3Hzie8"
   },
   "outputs": [],
   "source": [
    "## k-Means algorithm\n",
    "def kmeans(dataset, k, max_iter = 300, tol = 0.001):\n",
    "  \n",
    "    ## YOUR CODE STARTS HERE\n",
    "    # ...\n",
    "    \n",
    "    ## 1. Initiate SSE which is key metric in k-means clustering (sse = sum of squared error) into 'np.inf'\n",
    "    curr_sse = np.inf\n",
    "\n",
    "    ## 2. Clustering\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        ## (Re)Aassign datas to its closest centroids\n",
    "        # ...\n",
    "\n",
    "        prev_sse = curr_sse\n",
    "        ## Re-calculate the average of each cluster and calculate SSE.\n",
    "        #  ...\n",
    "\n",
    "        ## Plot center points\n",
    "        plt.figure(i)\n",
    "        c_df = pd.DataFrame(centroids).transpose()\n",
    "        plt.scatter(c_df.loc[:, 0], c_df.loc[:, 1], color='black', marker='x')\n",
    "\n",
    "        ## Plot assigned data\n",
    "        for key in cluster_memberships:\n",
    "            plt.scatter(*zip(*cluster_memberships[key]), alpha=0.2)\n",
    "            plt.title('k={} '.format(k) + ' SSE=' + str(curr_sse))\n",
    "\n",
    "        plt.show()\n",
    "        print('iteration#{} | prev_sse= {:.4f};  curr_sse= {:.4f}'.format(i, prev_sse, curr_sse))\n",
    "\n",
    "        # Terminal Condition\n",
    "        if (prev_sse - curr_sse) / curr_sse < tol:\n",
    "            break\n",
    "\n",
    "    return cluster_memberships, curr_sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYIduuPSzie9"
   },
   "source": [
    "\n",
    " <font color='blue'>\n",
    "\n",
    "**Q3: Before the iterations, how are the centroids defined?**<br>\n",
    "\n",
    "**Q4: One metric to evaluate the clustering results is sum of squared error (SSE). Describe the meaning of SSE in terms of the relationship between data and centroids**<br>\n",
    "\n",
    "**Q5: What is the terminal condition? Describe it with `tol` and `max_iter`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dT0TvJjbzie9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cluster_memberships, curr_sse = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQxzS1Xkzie9"
   },
   "source": [
    "----\n",
    "### Step(6) Using sklearn library\n",
    "- ___KMeans(n_clusters=)___ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmTB-6Y8zie9"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "## YOUR CODE STARTS HERE\n",
    "# model = ...\n",
    "# ...\n",
    "\n",
    "# result = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKH87Sq6zie-"
   },
   "source": [
    "- Check ___crosstab___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wkxpv-6zie-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = ...\n",
    "# ct = ...\n",
    "ct"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "9_kMeans_forstudent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
