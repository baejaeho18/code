{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# NLP Pipeline\n",
        "## 1. Text Information\n",
        "str_data = \"<html><h2>What is nlp??? </h2></html> \\nNatural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\\nThe study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\\n(In this post), you will discover what natural language processing is and why it is so important.\\nAfter reading this post, you will know => What natural language is and how it is different from other types of data.\"\n"
      ],
      "metadata": {
        "id": "1tQN_bX6nrKO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg8jjWickQgN",
        "outputId": "22865d25-ce17-4475-84e3-b2a69955f374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is nlp  \n",
            "natural language processing or nlp for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
            "the study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
            "in this post you will discover what natural language processing is and why it is so important\n",
            "after reading this post you will know  what natural language is and how it is different from other types of data\n"
          ]
        }
      ],
      "source": [
        "## 2. Text Cleaning\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "\n",
        "def remove_html(text_data):\n",
        "  soup = BeautifulSoup(text_data, 'lxml')\n",
        "  return soup.get_text()\n",
        "\n",
        "def remove_punctuation(text):\n",
        "  sent = []\n",
        "  for t in text.split(' '):\n",
        "    no_punct = \"\".join([c for c in t if c not in string.punctuation])\n",
        "    sent.append(no_punct)\n",
        "  sentence = \" \".join(s for s in sent)\n",
        "  return sentence\n",
        "\n",
        "def lower_sentence(text):\n",
        "  return text.lower()\n",
        "\n",
        "processed_text = remove_html(str_data)\n",
        "rm_punc_sentence = remove_punctuation(processed_text)\n",
        "sentence = lower_sentence(rm_punc_sentence)\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Tokenization & Text Lemmatization\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(sentence.strip())\n",
        "tok_lem_sentence = [(token.text, token.lemma_) for token in doc]\n",
        "print(tok_lem_sentence[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E65GgscxlHfp",
        "outputId": "de624b9d-3e1d-40e2-a079-a161933b859c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('what', 'what'), ('is', 'be'), ('nlp', 'nlp'), (' \\n', ' \\n'), ('natural', 'natural'), ('language', 'language'), ('processing', 'processing'), ('or', 'or'), ('nlp', 'nlp'), ('for', 'for'), ('short', 'short'), ('is', 'be'), ('broadly', 'broadly'), ('defined', 'define'), ('as', 'as')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Removing Stopwords  : 대명사\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(len(stop_words))\n",
        "\n",
        "lem_sentence = [token.lemma_ for token in doc]\n",
        "rmv_sw_sentence = [w for w in lem_sentence if not w in stop_words]\n",
        "removed_word = [w for w in lem_sentence if not w in rmv_sw_sentence]\n",
        "print(lem_sentence)\n",
        "print(rmv_sw_sentence)\n",
        "print(removed_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rrHbXkclUjP",
        "outputId": "ebfc056e-7abd-4a7f-ae33-8ea790eef6b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "['what', 'be', 'nlp', ' \\n', 'natural', 'language', 'processing', 'or', 'nlp', 'for', 'short', 'be', 'broadly', 'define', 'as', 'the', 'automatic', 'manipulation', 'of', 'natural', 'language', 'like', 'speech', 'and', 'text', 'by', 'software', '\\n', 'the', 'study', 'of', 'natural', 'language', 'processing', 'have', 'be', 'around', 'for', 'more', 'than', '50', 'year', 'and', 'grow', 'out', 'of', 'the', 'field', 'of', 'linguistic', 'with', 'the', 'rise', 'of', 'computer', '\\n', 'in', 'this', 'post', 'you', 'will', 'discover', 'what', 'natural', 'language', 'processing', 'be', 'and', 'why', 'it', 'be', 'so', 'important', '\\n', 'after', 'read', 'this', 'post', 'you', 'will', 'know', ' ', 'what', 'natural', 'language', 'be', 'and', 'how', 'it', 'be', 'different', 'from', 'other', 'type', 'of', 'datum']\n",
            "['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
            "['what', 'be', 'or', 'for', 'be', 'as', 'the', 'of', 'and', 'by', 'the', 'of', 'have', 'be', 'for', 'more', 'than', 'and', 'out', 'of', 'the', 'of', 'with', 'the', 'of', 'in', 'this', 'you', 'will', 'what', 'be', 'and', 'why', 'it', 'be', 'so', 'after', 'this', 'you', 'will', 'what', 'be', 'and', 'how', 'it', 'be', 'from', 'other', 'of']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. Encoding\n",
        "import numpy as np\n",
        "dictionary = {}\n",
        "\n",
        "def make_frequency_dict(text):\n",
        "  # Count the frequency\n",
        "  for word in text:\n",
        "    if word not in dictionary:\n",
        "      dictionary[word] = 0\n",
        "    dictionary[word] += 1\n",
        "\n",
        "make_frequency_dict(rmv_sw_sentence)\n",
        "vocab_sorted = sorted(dictionary.items(), key=lambda x:x[1], reverse = True)\n",
        "print(vocab_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EMu7N00l3I2",
        "outputId": "2de5cebf-0a8c-4eae-add3-32014ebe1925"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('natural', 5), ('language', 5), ('processing', 3), ('\\n', 3), ('nlp', 2), ('post', 2), (' \\n', 1), ('short', 1), ('broadly', 1), ('define', 1), ('automatic', 1), ('manipulation', 1), ('like', 1), ('speech', 1), ('text', 1), ('software', 1), ('study', 1), ('around', 1), ('50', 1), ('year', 1), ('grow', 1), ('field', 1), ('linguistic', 1), ('rise', 1), ('computer', 1), ('discover', 1), ('important', 1), ('read', 1), ('know', 1), (' ', 1), ('different', 1), ('type', 1), ('datum', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "\n",
        "for (word, frequency) in vocab_sorted:\n",
        "  # Cleaning: remove if frequency is less than 2\n",
        "  if frequency > 1:\n",
        "    i += 1\n",
        "    word_to_index[word] = i\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gWnnGUJpo5v",
        "outputId": "2f77e352-b399-45aa-a77f-aea2c31245df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'natural': 1, 'language': 2, 'processing': 3, '\\n': 4, 'nlp': 5, 'post': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['OOV'] = len(word_to_index) + 1\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DMkc3MNqI6N",
        "outputId": "b47ed81f-d71c-4c5e-e145-00a9381814a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'natural': 1, 'language': 2, 'processing': 3, '\\n': 4, 'nlp': 5, 'post': 6, 'OOV': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = []\n",
        "print(rmv_sw_sentence)\n",
        "for w in rmv_sw_sentence:\n",
        "  encoded.append(word_to_index.get(w, word_to_index['OOV']))\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAB_aFDVq6lr",
        "outputId": "4c159cc7-1287-44c1-c06c-721781b4cb1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
            "[5, 7, 1, 2, 3, 5, 7, 7, 7, 7, 7, 1, 2, 7, 7, 7, 7, 4, 7, 1, 2, 3, 7, 7, 7, 7, 7, 7, 7, 7, 4, 6, 7, 1, 2, 3, 7, 4, 7, 6, 7, 7, 1, 2, 7, 7, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Embedding (rather than one-hot encoding)\n",
        "!pip install gensim\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIW8qZzerLhJ",
        "outputId": "c4900d0a-d6a3-4b29-b8df-1c2a559735b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        " \"Be careful not to practice your righteousness in front of others to be seen by them If you do you will have no reward from your Father in heaven\",\n",
        " \"So when you give to the needy do not announce it with trumpets as the hypocrites do in the synagogues and on the streets to be honored by others Truly I tell you they have received their reward in full\",\n",
        " \"But when you give to the needy do not let your left hand know what your right hand is doing so that your giving may be in secret Then your Father who sees what is done in secret will reward you\",\n",
        " \"And when you pray do not be like the hypocrites for they love to pray standing in the synagogues and on the street corners to be seen by others Truly I tell you they have received their reward in full\",\n",
        " \"But when you pray go into your room close the door and pray to your Father who is unseen Then your Father who sees what is done in secret will reward you\",\n",
        " \"And when you pray do not keep on babbling like pagans for they think they will be heard because of their many words Do not be like them for your Father knows what you need before you ask him\",\n",
        " \"This then is how you should pray\",\n",
        " \"Our Father in heaven hallowed be your name your kingdom come your will be done on earth as it is in heaven Give us today our daily bread And forgive us our debts as we also have forgiven our debtors And lead us not into temptation but deliver us from the evil one\",\n",
        " \"For if you forgive other people when they sin against you your heavenly Father will also forgive you\",\n",
        " \"But if you do not forgive others their sins your Father will not forgive your sins\",\n",
        " \"When you fast do not look somber as the hypocrites do for they disfigure their faces to show others they are fasting Truly I tell you they have received their reward in full\",\n",
        " \"But when you fast put oil on your head and wash your face so that it will not be obvious to others that you are fasting but only to your Father who is unseen and your Father who sees what is done in secret will reward you\",\n",
        " \"Do not store up for yourselves treasures on earth where moths and vermin destroy and where thieves break in and steal\",\n",
        " \"But store up for yourselves treasures in heaven where moths and vermin do not destroy and where thieves do not break in and steal For where your treasure is there your heart will be also\",\n",
        " \"The eye is the lamp of the body If your eyes are healthy your whole body will be full of light\",\n",
        " \"But if your eyes are unhealthy your whole body will be full of darkness If then the light within you is darkness how great is that darkness\",\n",
        " \"No one can serve two masters Either you will hate the one and love the other or you will be devoted to the one and despise the other You cannot serve both God and money\",\n",
        " \"Therefore I tell you do not worry about your life what you will eat or drink or about your body what you will wear Is not life more than food and the body more than clothes\",\n",
        " \"Look at the birds of the air they do not sow or reap or store away in barns and yet your heavenly Father feeds them Are you not much more valuable than they\",\n",
        " \"Can any one of you by worrying add a single hour to your life\",\n",
        " \"And why do you worry about clothes See how the flowers of the field grow They do not labor or spin\",\n",
        " \"Yet I tell you that not even Solomon in all his splendor was dressed like one of these\",\n",
        " \"If that is how God clothes the grass of the field which is here today and tomorrow is thrown into the fire will he not much more clothe you—you of little faith\",\n",
        " \"So do not worry saying What shall we eat or What shall we drink or What shall we wear\",\n",
        " \"For the pagans run after all these things and your heavenly Father knows that you need them\",\n",
        " \"But seek first his kingdom and his righteousness and all these things will be given to you as well\",\n",
        " \"Therefore do not worry about tomorrow for tomorrow will worry about itself Each day has enough trouble of its own\"\n",
        "]"
      ],
      "metadata": {
        "id": "im3LmwKatzm_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [simple_preprocess(sentence) for sentence in sentences]\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100,\n",
        "                 window=5, min_count=1, workers=4)\n",
        "\n",
        "similar_words = model.wv.most_similar('faith', topn=5)\n",
        "print(f\"Words most similar to 'word2vec': {similar_words}\")\n",
        "\n",
        "similarity = model.wv.similarity('faith', 'give')\n",
        "print(f\"Similarity between the two ward: {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTW47Lm5t_MS",
        "outputId": "dc208b90-19e1-46df-9b4f-6aafdb15a65a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words most similar to 'word2vec': [('lamp', 0.28284162282943726), ('is', 0.23174726963043213), ('despise', 0.2183786928653717), ('whole', 0.2105974406003952), ('evil', 0.20408344268798828)]\n",
            "Similarity between the two ward: -0.15157455205917358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vector = model.wv['faith']\n",
        "print(f\"Vector representation of 'word2vec': {word_vector}\")\n",
        "\n",
        "vocab = list(model.wv.index_to_key)\n",
        "print(f\"Vocabulary: {vocab}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPlndXEBumHr",
        "outputId": "1f8073c1-2dbd-4887-bf39-2250bde861e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector representation of 'word2vec': [-0.0056755  -0.00826638 -0.00915298  0.00379124 -0.00217069  0.00963383\n",
            " -0.00820941  0.00515155  0.00953387  0.0029702  -0.00565649  0.00648765\n",
            "  0.00685388 -0.00756669  0.00396194 -0.00143258  0.00219368 -0.00854774\n",
            "  0.00076148 -0.0060312  -0.00681356 -0.00522335 -0.00930255 -0.00935273\n",
            " -0.00565238 -0.00412352  0.00188261 -0.00974641 -0.00310949 -0.0045515\n",
            "  0.00449779  0.00462821 -0.00412186  0.00852492 -0.00706794  0.00865432\n",
            " -0.00199032  0.00070295  0.00207171  0.00690386 -0.00415363 -0.00103651\n",
            "  0.00485524  0.00114699  0.00081935  0.00878539 -0.00836978 -0.00603853\n",
            " -0.00695298 -0.00761339 -0.00675022 -0.00014128 -0.00110848  0.00652218\n",
            "  0.00946799 -0.00053769  0.00061736 -0.0086329   0.00348209 -0.0065323\n",
            "  0.00597688  0.0002868   0.004935   -0.00662508  0.00228451 -0.00908144\n",
            " -0.00731483 -0.00247767 -0.00576591 -0.00583857 -0.0058863   0.00958526\n",
            "  0.0010163  -0.0017593  -0.0034525  -0.00187125 -0.0017161  -0.00441008\n",
            " -0.00483987 -0.00813112  0.00792916  0.00501041 -0.00613955  0.00030213\n",
            "  0.002537    0.00986856 -0.00233559  0.00901333  0.00719339 -0.00482459\n",
            " -0.00823435  0.00974694  0.0040298   0.0053621  -0.00379081  0.009179\n",
            " -0.00202117 -0.00618594  0.00778677  0.00905201]\n",
            "Vocabulary: ['you', 'your', 'the', 'and', 'not', 'will', 'do', 'in', 'be', 'is', 'to', 'they', 'father', 'of', 'what', 'for', 'but', 'or', 'when', 'that', 'reward', 'if', 'one', 'their', 'on', 'pray', 'others', 'full', 'who', 'tell', 'body', 'as', 'about', 'worry', 'have', 'are', 'forgive', 'where', 'more', 'like', 'done', 'how', 'our', 'us', 'we', 'secret', 'then', 'them', 'heaven', 'so', 'by', 'store', 'his', 'also', 'tomorrow', 'heavenly', 'darkness', 'give', 'these', 'it', 'life', 'clothes', 'shall', 'other', 'into', 'all', 'received', 'sees', 'hypocrites', 'truly', 'than', 'up', 'sins', 'moths', 'fast', 'destroy', 'yourselves', 'vermin', 'fasting', 'treasures', 'from', 'righteousness', 'today', 'earth', 'kingdom', 'need', 'knows', 'pagans', 'unseen', 'love', 'break', 'seen', 'hand', 'synagogues', 'needy', 'no', 'thieves', 'look', 'steal', 'wear', 'therefore', 'eat', 'serve', 'things', 'light', 'god', 'drink', 'much', 'whole', 'yet', 'eyes', 'field', 'can', 'see', 'flowers', 'why', 'left', 'hour', 'single', 'honored', 'add', 'streets', 'grow', 'let', 'any', 'worrying', 'know', 'spin', 'right', 'valuable', 'doing', 'giving', 'may', 'feeds', 'barns', 'away', 'reap', 'sow', 'labor', 'trumpets', 'even', 'front', 'after', 'seek', 'first', 'given', 'well', 'itself', 'each', 'solomon', 'day', 'has', 'practice', 'enough', 'trouble', 'careful', 'run', 'saying', 'faith', 'little', 'clothe', 'he', 'fire', 'thrown', 'here', 'which', 'grass', 'dressed', 'was', 'announce', 'splendor', 'with', 'birds', 'air', 'food', 'at', 'disfigure', 'forgiven', 'debtors', 'lead', 'temptation', 'deliver', 'evil', 'two', 'people', 'sin', 'against', 'great', 'within', 'its', 'somber', 'faces', 'standing', 'show', 'unhealthy', 'put', 'oil', 'head', 'wash', 'face', 'obvious', 'only', 'healthy', 'lamp', 'eye', 'heart', 'there', 'masters', 'either', 'debts', 'hate', 'street', 'corners', 'go', 'treasure', 'room', 'close', 'door', 'keep', 'babbling', 'think', 'heard', 'because', 'many', 'words', 'before', 'ask', 'him', 'this', 'money', 'should', 'hallowed', 'name', 'both', 'come', 'cannot', 'despise', 'devoted', 'daily', 'bread', 'own']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "pretrained_model = api.load('word2vec-google-news-300')\n",
        "model_path = '/cotent/drive/MyDrive/Colab_Notebooks/Intro2AI/word2vec-google-news-300.model'\n",
        "pretrained_model.save(model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs2qGxXwvAuk",
        "outputId": "3615289f-3f05-4f71-e631-c69449c031b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================-----------------] 66.1% 1098.6/1662.8MB downloaded"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.models.keyedvectors\n",
        "pretrained_model = KeyedVectors.load(model_path)\n",
        "print(\"Model loaded successfully\")"
      ],
      "metadata": {
        "id": "R2PVc0WgvhQn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}